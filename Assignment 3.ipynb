{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training accuracy Validation accuracy\n",
      "DT         43.485082           83.469559\n",
      "RF         28.979606           46.785785\n",
      "GB          3.222085             25.8525\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_DT = DecisionTreeRegressor(max_depth = 5, random_state = 0)\n",
    "model_RF = RandomForestRegressor(max_depth = 5, random_state = 0)\n",
    "model_GB = GradientBoostingRegressor(max_depth = 5, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "scores_DT = cross_validate(model_DT, X_train, y_train, cv = 5,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                       return_train_score=True)\n",
    "\n",
    "scores_RF = cross_validate(model_RF, X_train, y_train, cv = 5,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                       return_train_score=True)\n",
    "\n",
    "scores_GB = cross_validate(model_GB, X_train, y_train, cv = 5,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                       return_train_score=True)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['Training accuracy', 'Validation accuracy'],\n",
    "                       index=['DT', 'RF', 'GB'])\n",
    "\n",
    "\n",
    "results.at['DT', 'Training accuracy'] = -scores_DT['train_score'].mean()\n",
    "results.at['DT', 'Validation accuracy'] = -scores_DT['test_score'].mean()\n",
    "\n",
    "results.at['RF', 'Training accuracy'] = -scores_RF['train_score'].mean()\n",
    "results.at['RF', 'Validation accuracy'] = -scores_RF['test_score'].mean()\n",
    "\n",
    "results.at['GB', 'Training accuracy'] = -scores_GB['train_score'].mean()\n",
    "results.at['GB', 'Validation accuracy'] = -scores_GB['test_score'].mean()\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training accuracy Validation accuracy\n",
      "DT          0.849106            0.706702\n",
      "RF          0.899452            0.837136\n",
      "GB          0.988827            0.910476\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "scores_DT = cross_validate(model_DT, X_train, y_train, cv = 5,\n",
    "                        scoring='r2',\n",
    "                       return_train_score=True)\n",
    "\n",
    "scores_RF = cross_validate(model_RF, X_train, y_train, cv = 5,\n",
    "                        scoring='r2',\n",
    "                       return_train_score=True)\n",
    "\n",
    "scores_GB = cross_validate(model_GB, X_train, y_train, cv = 5,\n",
    "                        scoring='r2',\n",
    "                       return_train_score=True)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['Training accuracy', 'Validation accuracy'],\n",
    "                       index=['DT', 'RF', 'GB'])\n",
    "\n",
    "\n",
    "results.at['DT', 'Training accuracy'] = scores_DT['train_score'].mean()\n",
    "results.at['DT', 'Validation accuracy'] = scores_DT['test_score'].mean()\n",
    "\n",
    "results.at['RF', 'Training accuracy'] = scores_RF['train_score'].mean()\n",
    "results.at['RF', 'Validation accuracy'] = scores_RF['test_score'].mean()\n",
    "\n",
    "results.at['GB', 'Training accuracy'] = scores_GB['train_score'].mean()\n",
    "results.at['GB', 'Validation accuracy'] = scores_GB['test_score'].mean()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. Comparing to Linear Models:\n",
    "   The results of all three models tested in this assignment outperform the linear model from the previous assignment.\n",
    "   The validation R2 scores are all notably higher than the linear model, with the best being 0.91 for GB (indicating a better fit of the data). Furthermore, the validation MSE's are all lower, with the best being 25.9 also for GB (showing less error and better model performance). Just as a comparison, the linear model's validation MSE was 93.6 and its validation R2 value was 0.64, both worse then the Gradient Boosting model.\n",
    "  \n",
    "2. Model Selection:\n",
    "   Based on the results, I would select the Gradient Boosting model (GB) as it appears to be the most suitable choice for this dataset. It has the highest validation r2 score (0.91) and the lowest validation MSE (25.9). It also has the best training accuracy scores. This would suggest that the Gradient Boosting model provides the best balance between fitting the data well and generalizing to unknown data. It is the best model of the three tested.\n",
    "  \n",
    "3. Increasing Accuracy of Tree-Based Models:\n",
    "   One way to increase the accuracy of tree-based models is to perform hyperparameter tuning. This involves systematically searching for the best combination of hyperparameters (e.g., max depth, number of trees, learning rate) to optimize the model's performance.\n",
    "   Another way to increase the accuracy is to create new features or modify existing ones that might capture important patterns in the data. This can enhance the model's ability to represent complex relationships. Basically put an emphasis on the features that are important in influencing the predictive model correctly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "Most of the code was sourced from my own knowledge as well as the material that has been covered so far in the course (lab notebooks covering similar content). I completed the steps in the order that they are outlined. \n",
    "For this part of the assignment I did use generative AI for one specific challenge I encountered. The challenge I experienced is figuring out the correct piece of code to get the average of the array of MSE and r2 values I was getting due to the multiple folds. I prompted the AI by asking it to calculate the average MSE value from the results of a cross_validate operation. I did not need to change the AI output and it helped me to understand how to isolate the part of the cross_validate result I needed and then get its average by using the mean() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (178, 13)\n",
      "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y: (178,)\n",
      "Type of y: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "data = pd.read_csv('wine/wine.data', names = ['class', 'Alcohol', 'Malicacid', 'Ash',\n",
    "                                              'Alcalinity_of_ash', 'Magnesium', 'Total_phenols',\n",
    "                                              'Flavanoids', 'Nonflavanoid_phenols', 'Proanthocyanins',\n",
    "                                              'Color_intensity', 'Hue',\n",
    "                                              '0D280_0D315_of_diluted_wines', 'Proline'])\n",
    "\n",
    "X = data.drop(columns = 'class')\n",
    "# The class columm is the target vector\n",
    "y = data['class']\n",
    "\n",
    "print(\"Size of X: \" + str(X.shape))\n",
    "print(\"Type of X: \" + str(type(X)))\n",
    "print(\"Size of y: \" + str(y.shape))\n",
    "print(\"Type of y: \" + str(type(y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
      "0    14.23       1.71  2.43               15.6        127           2.80   \n",
      "1    13.20       1.78  2.14               11.2        100           2.65   \n",
      "2    13.16       2.36  2.67               18.6        101           2.80   \n",
      "3    14.37       1.95  2.50               16.8        113           3.85   \n",
      "4    13.24       2.59  2.87               21.0        118           2.80   \n",
      "\n",
      "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   0D280_0D315_of_diluted_wines  Proline  \n",
      "0                          3.92     1065  \n",
      "1                          3.40     1050  \n",
      "2                          3.17     1185  \n",
      "3                          3.45     1480  \n",
      "4                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in this dataset\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "if X.isna().sum().sum() == 0:\n",
    "    print(\"There are no missing values in this dataset\")\n",
    "else:\n",
    "    X = X.fillna(X.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of wine: 2, # of samples: 71\n",
      "Type of wine: 1, # of samples: 59\n",
      "Type of wine: 3, # of samples: 48\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "for value, count in y.value_counts().items():\n",
    "    print(f\"Type of wine: {value}, # of samples: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Data Size Training accuracy Validation accuracy\n",
      "DTC  (178, 13)          0.991939            0.878667\n",
      "SVC  (178, 13)          0.671313            0.644333\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_DTC = DecisionTreeClassifier(max_depth = 3)\n",
    "model_SVC = SVC()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "scores_DTC = cross_validate(model_DTC, X_train, y_train, cv = 5,\n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "scores_SVC = cross_validate(model_SVC, X_train, y_train, cv = 5,\n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "results = pd.DataFrame(columns=['Data Size', 'Training accuracy', 'Validation accuracy'],\n",
    "                       index=['DTC', 'SVC'])\n",
    "\n",
    "results.at['DTC', 'Data Size'] = X.shape\n",
    "results.at['DTC', 'Training accuracy'] = scores_DTC['train_score'].mean()\n",
    "results.at['DTC', 'Validation accuracy'] = scores_DTC['test_score'].mean()\n",
    "\n",
    "results.at['SVC', 'Data Size'] = X.shape\n",
    "results.at['SVC', 'Training accuracy'] = scores_SVC['train_score'].mean()\n",
    "results.at['SVC', 'Validation accuracy'] = scores_SVC['test_score'].mean()\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree classifier gave the highest accuracy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "print(\"The decision tree classifier gave the highest accuracy\\n\")\n",
    "model_DTC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(170.97222222222223, 0.5, 'true value')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, model_DTC.predict(X_test))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.95      0.97        59\n",
      "           2       0.96      0.99      0.97        71\n",
      "           3       0.98      1.00      0.99        48\n",
      "\n",
      "    accuracy                           0.98       178\n",
      "   macro avg       0.98      0.98      0.98       178\n",
      "weighted avg       0.98      0.98      0.98       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have your true labels and predicted labels\n",
    "true_labels = y\n",
    "predicted_labels = model_DTC.predict(X)\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "2. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "3. How many samples were incorrectly classified in step 5.2? \n",
    "4. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1. The training and validation accuracy change significantly based on the method used. The Decision Tree Classifier (DTC) achieved higher training accuracy (99.2%) compared to the Support Vector Classifier (SVC) (67.2%). Furthermore, in terms of validation accuracy, DTC also outperforms SVC (87.0% for DTC vs. 64.4% for SVC). Therefore, for this dataset it is clear that DTC is the superior model.\n",
    "\n",
    "2. One reason the SVC may not have performed well is the complexity of the data. As the SVC is kernelized it is better suited for non-linear data. Therefore, it is possible that the dataset is better suited to a linear model, and that is why the SVC underperformed.\n",
    "Another reason could be the hyperparameter setting. The default hyperparameters of the SVC model might not be well suited for this dataset. In this case, parameter tuning was not performed, and it is reasonable to assume that with some tuning, a better model could have been achieved. \n",
    "\n",
    "3. I ran the confusion matrix on both models so it is easier to visualize the samples incorrectly classified, and I summed the incorrect ones manually. For the DTC model there were only 3 samples incorrectly classified. For the SVC however, there were 12 samples incorrectly classified, the most common being sample 3 being misclassified as sample 2 (7 times).\n",
    "\n",
    "4. In this specific example, I am not sure a false positive (precision) or false negative (recall) would matter more than the other as in both cases, you are mislabeling a wine. You either assign it the wrong wine class through a false positive, or through a false negative, either way the wine has been mislabeled. Therefore, in this context I don't believe it matters which one is maximized, as the consequences of having a false positive or a false negative are equal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "Most of the code was sourced from my own knowledge as well as the material that has been covered so far in the course (lab notebooks covering similar content). I completed the steps in the order that they are outlined. \n",
    "I did use generative AI for one specific part in the second half. I used it to help me generate the classification report. I just prompted it by asking it how I would generate a classification report. I then took its output (which was just a generic version of the classification report function) and adapted it to my requirements, using my test and predicted target vector values. This was probably the only challenge for this part fo the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "### Part One\n",
    "\n",
    "Decision Tree (DT):\n",
    "\n",
    "The training accuracy for the Decision Tree is quite high, at 0.849. However, the validation accuracy is lower, at 0.707. This drop in accuracy between training and validation sets suggests that the Decision Tree is likely overfitting the training data. It's capturing some noise and maybe not generalizing very well. This aligns with the lecture discussions about decision trees' tendency to overfit.\n",
    "\n",
    "Random Forest (RF):\n",
    "\n",
    "The training accuracy for the Random Forest is also quite high, at 0.899. Similar to the Decision Tree however, the validation accuracy is lower, at 0.837. Like the Decision Tree, the Random Forest might be exhibiting overfitting tendencies, but it is clearly better than the single Decision Tree maybe due to it utilizing multiple decision trees and averaging their results.\n",
    "\n",
    "Gradient Boosting (GB):\n",
    "\n",
    "The training accuracy for Gradient Boosting is substantially higher, at 0.989, compared to the previous models. The validation accuracy for Gradient Boosting is also significantly higher, at 0.910, and is better than the previous models. Gradient Boosting is showing significantly better generalization performance compared to Decision Trees and Random Forests. This aligns with the lecture discussions about ensemble methods, like Gradient Boosting, being effective at reducing overfitting and improving model accuracy.\n",
    "\n",
    "### Part Two\n",
    "\n",
    "The Decision Tree Classifier achieved a very high training and validation accuracy. This would suggest that DTC is robust to overfitting, as it generalizes well to the validation data.\n",
    "\n",
    "The Support Vector Classifier has a lower training accuracy compared to the DTC, indicating that it doesn't fit the training data as closely. The validation accuracy is also lower, but the drop from training to validation accuracy is smaller compared to the DTC. This suggests that the SVC has achieved a better balance between training and validation performance but still not as good of a model overall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I enjoyed this assignment because by working through all the steps I gained a much better understanding of the models themselves, how they work, and their output. I also learned more about the methods that we have at our disposal (like cross_validate) and what they fundamentally mean. This assignment also helped reiterate how important it is to try different models and pick the model best suited to your data.\n",
    "I liked that the reflection questions made me actually think about what I was doing and how the models worked, instead of just plugging in the methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Training accuracy Validation accuracy\n",
      "SVC           0.671313            0.644333\n",
      "LSVC          0.990161            0.955079\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_LSVC = LinearSVC(max_iter=5000, dual = 'auto')\n",
    "\n",
    "scores_LSVC = cross_validate(model_LSVC, X, y, cv = 5,\n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "results = pd.DataFrame(columns=['Training accuracy', 'Validation accuracy'],\n",
    "                       index=['SVC', 'LSVC'])\n",
    "\n",
    "results.at['SVC', 'Training accuracy'] = scores_SVC['train_score'].mean()\n",
    "results.at['SVC', 'Validation accuracy'] = scores_SVC['test_score'].mean()\n",
    "\n",
    "results.at['LSVC', 'Training accuracy'] = scores_LSVC['train_score'].mean()\n",
    "results.at['LSVC', 'Validation accuracy'] = scores_LSVC['test_score'].mean()\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "LinearSVC is a linear support vector machine, and it's suited for problems that have linearly separable classes or datasets where a linear decision boundary is a good approximation. For this dataset, it is clear that using the LinearSVC model improves the results greatly as both the training and validation accuracy increase by about 30% as compared to the general SVC model. This means that the wine dataset likely has linearly separable classes and therefore, it is better to use the LinearSVC model as the decision boundary it draws is linear.\n",
    "\n",
    "I believe the LinearSVC model is a good fit for the data because of the very high validation accuracy score.\n",
    "Furthermore, there are some other advantages to using it if possible. It is a simpler model, and therefore it has a faster convergence as well as a reduced risk of overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
